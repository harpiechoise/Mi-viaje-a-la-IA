{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como funcionan \n",
    "\n",
    "Supongamos que tengo X parametros de entrada, tenemos parametros como \n",
    "\n",
    "Parametros de X: (**Area**, **Numero de habitaciones**, **Distancia de la ciudad en millas**, **Y antiguedad de la propiedad**) \n",
    "\n",
    "y tenemos una salida Y: **Precio de la propiedad** \n",
    "\n",
    "y supongamos que tenemos solo la entrada conectada a la salida, y las neuronas de entrada solo son las correspondientes a nuestras entradas es decir 4, lo que pasaria esque todas las entradas estarian conectadas a la salida por 4 pesos.\n",
    "\n",
    "la suma de los pesos seria: (W1*X1 + W2*X2 + W3*X3 + W4*X4) \n",
    "\n",
    "\\begin{equation}\n",
    "    \\sum_{i=0}^{m}(w_i * x_i) \n",
    "\\end{equation}\n",
    "\n",
    "pero en caso de que agregaramos una capa escondida se veria como esto\n",
    "\n",
    "![Perceptron Multicapa](https://upload.wikimedia.org/wikipedia/commons/6/64/RedNeuronalArtificial.png)\n",
    "\n",
    "Es decir todos los X irian conectados a todas las cuantas neuronas tengamos en la capa escondida, y lo que pasa con esto esque esta neurona se activara solo cuando su criterio lo diga por ejemplo si con la funcion de activacion, es decir, evaluara las entradas que se le dan y retornara una activacion > 0 si sus valores asi lo indican resultado de una serie de calculos, realmente a la neurona no le importa que valores le entregas ni el problema a resolver solo retornar un valor que contribuye a acortar la distancia entre una entrada y una salida, y para esto reconocera patrones valorando entre los datos de entrada y salida para intentar ajustarse a esa funcion que le pasamos y al tener mas de una neurona, ayudamos a que cada parametro que pasamos por la red tenga una validacion mas precisa, en un resumen, esto funciona como un gran filtro, que discrimina entre los parametros que contribuyen a resolver un problema y las que no sirven. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decenso estocástico de gradiente\n",
    "\n",
    "El **Decenso de gradiente** es un metodo muy eficiente para minimizar y optimizar la **Funcion de costo** sin esta formula no se podria resolver de manera tan eficiente un problema de cualquier tipo, que lo que hace exactamente es buscar los minimos globales y no quedarse en tan solo encontrar minimos locales, para asi tener una relacion mas precisa entre la entrada y la salida\n",
    "\n",
    "Formula:\n",
    "\n",
    "\\begin{equation}\n",
    "MSE_{(Y',Y)}\\frac{1}{2}(Y'-Y)^1\n",
    "\\end{equation}\n",
    "\n",
    "donde Y' es la prediccion de los datos e Y son los datos reales por lo que cuando graficamos el funcionamiento de esta funcion se veria algo como esto \n",
    "\n",
    "![Decenso gradiente](https://qph.fs.quoracdn.net/main-qimg-25913bb0aa0193a5885640a64e8d490f)\n",
    "\n",
    "El metodo de **descenso de gradiente** es una funcion que se implementa para optimizar la funcion de **costo** o **perdida** lo su funcionamiento es simple, despues de una iteracion de la red por los datos da otra iteracion que se llama validacion pasando los datos iniciales y prediciendo con cada uno de ellos un valor aproximado **Y'** y luego de predecir este valor aproximado se calcula la media de los errores al cuadrado **MSE** que es la media de la prediccion de la maquina y la media de los datos reales, o lo que deberia ser predecido por la maquina **Y** lo cual se eleva al cuadrado y se obtiene un numero que luego veremos para que sirve.\n",
    "\n",
    "**¿Que logramos con esto?**\n",
    "\n",
    "Cuando hablamos de minimos nos referemos a la distancia entre la prediccion de la maquina y los datos reales, mientras menos distancia haya entre ellos mas preciso se vuelve el predictor cuando le pasemos nuevos ejemplos que nunca ha visto en el set de datos original\n",
    "\n",
    "Pero para aplicar el descenso de gradiente hace falta un requisito el cual es tener una funcion de error convexa donde el minimo sera el punto mas bajo de la misma y solo haya un minimo al cual se le atribuye el nombre de minimo local ¿Pero que pasa si la funcion no es convexa?\n",
    "\n",
    "y se ve algo como esto\n",
    "\n",
    "![Funcion No Convexa](https://frnsys.com/ai_notes/assets/nonconvex.svg)\n",
    "\n",
    "aqui es donde se origina el problema porque nuestra funcion por si sola solo puede alcanzar un minimo pero no estamos seguros de que si ese minimo es el minimo local o el global, entonces aplicar la funcion\n",
    "\n",
    "\\begin{equation}\n",
    "MSE_{(Y',Y)}\\frac{1}{2}(Y'-Y)^1\n",
    "\\end{equation}\n",
    "\n",
    "No nos serviria porque nos llevaria al primer minimo local, por lo que seria una red neuronal para nada precisa, ya que quizas ese minimo local no es la verdadera distancia minima entre **Y'** e **Y** aqui entra el concepto de \n",
    "\n",
    "**Descenso estocastico de gradiente**\n",
    "\n",
    "El descenso estocastico de gradiente no requiere que una funcion sea convexa por lo cual puede hayar el **minimo global** de cualquier tipo de funcion de costo que la gran diferencia esque va a calcular la funcion de descenso de gradiente pero, ajustara todos los pesos por cada vez que se le presente un dato permitiendo asi seguir buscando el minimo global de la funcion por lo que tendremos algo como esto, siendo cada anillo una minima local\n",
    "\n",
    "Otro parametro a tomar en cuenta es el Learning Rate o Razon de aprendizaje el cual ajustara la velocidad de descenso el cual no puede ser muy alto porque o si no nunca llegara al minimo global ni muy bajo porque o si no le tomara mucho tiempo en llegar al minimo global, la razon de aprendizaje lo que hara es dar un paso hacia la direccion del minimo global, es decir el largo de las flechas de la imagen es el correspondiente a nuestra razon de aprendizaje\n",
    "\n",
    "![Batch Gradient Descent](https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w10_large_scale_ml/largescaleml3.png)\n",
    "\n",
    "Entonces para marcar una diferencia mas notoria\n",
    "\n",
    "El descenso de gradiente por baches:\n",
    "\n",
    "1. Paso 1 hace una iteracion completa\n",
    "2. Calcula la distancia del error\n",
    "3. Ajusta los pesos\n",
    "\n",
    "El descenso de gradiente estrocastico:\n",
    "1. Toma 1 dato\n",
    "2. Calcula el error\n",
    "3. Ajusta los pesos\n",
    "4. Y repite lo mismo con todo el set de datos\n",
    "\n",
    "una impresion que podria darse esque **El descenso de gradiente estrocastico** vs **El descenso de gradiente por baches** debe ser mucho mas lento pero en verdad el estrocastico es mucho mas rapido y es porque no necesesita cargar todos los datos en la memoria y hacer los calculos si no tomar dato por dato y calcular el resultado para cada uno de ellos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation o propagacion hacia atras\n",
    "\n",
    "entonces vimos que primero tenemos que hacer una propagacion hacia adelante que es pasar todos los datos por la red hasta la salida y se calculaba el error y se asplicaba el descenso de gradiente y ese nos daba un numero que se correspondia entre la distancia entre las predicciones y los datos reales.\n",
    "\n",
    "ahora con ese numero se deben ajustar los pesos hacia atras, es decir desde la salida hacia la red, se deben ajustar todos los pesos para acortar de manera real la distancia entre la salida aproximada y la salida real eso se llama **Back Propagation** algo a recordad es que el **Back Propagation** es algoritmo avanzado que se da de matematicas sofisticadas para ajustar todos los pesos al mismo tiempo, es decir, todos los pesos son ajustados simultaneamente.\n",
    "\n",
    "Si quieres programarlo, debes tener muy en cuenta que todos los pesos **deben** ser actualizados al mismo tiempo, o si no el algoritmo no funcionara y esta es la clave del algoritmo de **back propagation** si quieres saber las matematicas exactas de este algoritmo pasate por este link\n",
    "\n",
    "[Back Propagation](http://neuralnetworksanddeeplearning.com/chap2.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenando una red neuronal artificial\n",
    "\n",
    "Ahora vamos a ver paso a paso el flujo del proceso de como entrenar una red neuronal artificial\n",
    "\n",
    "1. Inicializamos de manera aleatoria uniforme nuestros pesos con valores cercanos a 0 pero no iguales a 0\n",
    "\n",
    "\n",
    "2. Le pasamos la primera observacion al modelo tanto la entrada como la salida real \n",
    "\n",
    "\n",
    "3. Propagamos los datos por nuestra red neuronal aplicando las funciones de activacion para cada capa hasta la de salida para obtener nuestra primera prediccion en la salida Y\n",
    "\n",
    "4. Comparamos el resultado de la prediccion del primero resultado con el resultado real y sacamos el error\n",
    "\n",
    "\n",
    "5. Hacemos la propagacion hacia atras para ajustar los pesos en base a nuestro error y dar el paso correspondiente a lo que nuestra razon de aprendizaje decida\n",
    "\n",
    "\n",
    "6. Repetir del 1 - 5 hasta pasar todas las observaciones correspondientes\n",
    "\n",
    "\n",
    "7. Una vez pasados todos los datos, repetirlo a lo largo de todas las epocas esto hara que nuestra read aprenda mejor mejor y mejor y obtener resultados mas precisos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
